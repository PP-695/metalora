# Class-aware LoRA configuration for long-tailed learning
# Extends standard FLoRA with class-aware meta-parameters

use_flora: True
use_meta: True
use_class_aware: True

flora:
  arch:
    modules: ["q", "k", "v", "out", "mlp1", "mlp2"]
    layers: [0,1,2,3,4,5,6,7,8,9,10,11]
    alpha: 1.0
    rank: 8  # Base rank

# Class-aware settings
class_aware:
  num_class_groups: 3  # head, medium, tail
  class_grouping_strategy: "threshold"  # or "frequency"

  # Thresholds for grouping (used with threshold strategy)
  head_threshold: 100  # Classes with >= 100 samples
  tail_threshold: 20   # Classes with < 20 samples

  # Initial rank factors per group
  head_rank_factor: 0.5   # Head classes use lower rank (less adaptation needed)
  tail_rank_factor: 2.0   # Tail classes use higher rank (more adaptation needed)

  # Initial alpha factors per group
  head_alpha_factor: 0.5  # Head classes use lower alpha
  tail_alpha_factor: 2.0  # Tail classes use higher alpha

# Gap 10: COCL-style loss components
cocl:
  use_ocl: False  # Enable Outlier Class Learning
  use_tail_proto: False  # Enable tail prototype learning
  use_head_debias: False  # Enable debiased head loss
  
  # Loss weights
  lambda_ocl: 0.5  # Weight for OCL loss
  lambda_tail_proto: 0.3  # Weight for tail prototype loss
  lambda_head_debias: 0.1  # Weight for head debiasing loss
  
  # OCL parameters
  ocl_weight: 1.0  # Weight for OOD samples in OCL
  
  # Tail prototype parameters
  tail_proto_temperature: 0.07  # Temperature for contrastive learning
  tail_proto_margin: 0.1  # Margin for tail-OOD separation
  
  # Head debiasing parameters
  head_debias_penalty: 0.1  # Penalty weight for head over-confidence
  
  # Calibration parameters (for inference)
  use_logit_calibration: False  # Enable calibrated logit adjustment at test time
  tau_calibrate: 1.0  # Temperature for logit calibration (0=no adjustment, 1=full)

# Gap 10: OOD dataset configuration
ood:
  use_ood: False  # Enable auxiliary OOD data
  ood_dataset: ""  # Path or name of OOD dataset (e.g., "tinyimages", "places365")
  ood_data_path: ""  # Path to OOD data
  ood_batch_size: 32  # Batch size for OOD data
  ood_num_samples: 10000  # Number of OOD samples to use (0 = use all)

# Gap 10: EAT-style tail augmentation
tail_augmentation:
  use_tail_cutmix: False  # Enable CutMix for tail classes
  tail_cutmix_alpha: 0.9999  # Beta distribution parameter (high = more tail preserved)
  tail_cutmix_prob: 0.5  # Probability of applying CutMix
  use_ood_paste: False  # Paste tail patches into OOD images
  apply_to_medium: False  # Also apply augmentation to medium classes

# Gap 10: OOD detection evaluation
ood_eval:
  enable: False  # Enable OOD detection metrics during evaluation
  ood_test_datasets: []  # List of OOD test datasets (e.g., ["textures", "svhn", "lsun"])
  ood_metric: "msp"  # OOD score: "msp" (max-softmax), "energy", "odin"
  compute_auroc: True  # Compute AUROC
  compute_aupr: True  # Compute AUPR
  compute_fpr95: True  # Compute FPR@95

# Gap 10: Advanced visualizations
visualization:
  enable: False  # Enable advanced visualizations
  save_confmat: True  # Save confusion matrix heatmap
  save_per_class_acc: True  # Save per-class accuracy plot
  save_tsne: False  # Save t-SNE embeddings (computationally expensive)
  save_calibration: True  # Save calibration curves
  plot_dir: "output/plots"  # Directory for saving plots
